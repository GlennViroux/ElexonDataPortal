{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79c3948f-7f98-4be1-ad7d-d4e0bec1df4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#default_exp dev.docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f718f55f",
   "metadata": {},
   "source": [
    "# Documentation\n",
    "\n",
    "This notebook documents the documentation utility functions developed for disseminating this research\n",
    "\n",
    "<br>\n",
    "\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9ba10d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#exports\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import junix\n",
    "from html.parser import HTMLParser\n",
    "from nbdev.export2html import convert_md\n",
    "\n",
    "import os\n",
    "import re\n",
    "import codecs\n",
    "from tqdm import tqdm\n",
    "from warnings import warn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b217f52",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### User Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58b2992e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_nbs_dir = '../nbs'\n",
    "docs_dir = '../docs'\n",
    "docs_nb_img_dir = f'{docs_dir}/img/nbs'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9d8a75",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Converting the Notebooks to Documentation\n",
    "\n",
    "We'll first convert the notebooks to markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ca576f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#exports\n",
    "def convert_file_to_json(filepath):\n",
    "    with open(filepath, 'r', encoding='utf8') as f:\n",
    "        contents = f.read()\n",
    "        f.close()\n",
    "\n",
    "    return json.loads(contents)\n",
    "\n",
    "junix.exporter.convert_file_to_json = convert_file_to_json\n",
    "\n",
    "def encode_file_as_utf8(fp):\n",
    "    with codecs.open(fp, 'r') as file:\n",
    "        contents = file.read(1048576)\n",
    "        file.close()\n",
    "\n",
    "        if not contents:\n",
    "            pass\n",
    "        else:\n",
    "            with codecs.open(fp, 'w', 'utf-8') as file:\n",
    "                file.write(contents)\n",
    "            \n",
    "def convert_nb_to_md(nb_file, nbs_dir, docs_nb_img_dir, docs_dir):\n",
    "    if os.path.exists(docs_nb_img_dir) is False:\n",
    "        os.makedirs(docs_nb_img_dir)\n",
    "\n",
    "    nb_fp = f'{nbs_dir}/{nb_file}'\n",
    "    junix.export_images(nb_fp, docs_nb_img_dir)\n",
    "    convert_md(nb_fp, docs_dir, img_path=f'{docs_nb_img_dir}/', jekyll=False)\n",
    "\n",
    "    md_fp =  docs_dir + '/'+ nb_file.replace('.ipynb', '') + '.md'\n",
    "    encode_file_as_utf8(md_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05bb95e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_file = '01-utils.ipynb'\n",
    "\n",
    "convert_nb_to_md(nb_file, dev_nbs_dir, docs_nb_img_dir, docs_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3642082",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "We'll then parse the HTML tables into markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ac369f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#exports\n",
    "class MyHTMLParser(HTMLParser):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.tags = []\n",
    "    \n",
    "    def handle_starttag(self, tag, attrs):\n",
    "        self.tags.append(self.get_starttag_text())\n",
    "\n",
    "    def handle_endtag(self, tag):\n",
    "        self.tags.append(f\"</{tag}>\")\n",
    "        \n",
    "get_substring_idxs = lambda string, substring: [num for num in range(len(string)-len(substring)+1) if string[num:num+len(substring)]==substring]\n",
    "\n",
    "def convert_df_to_md(df):\n",
    "    idx_col = df.columns[0]\n",
    "    df = df.set_index(idx_col)\n",
    "    \n",
    "    if not isinstance(df.index.name, str):\n",
    "        df.index.name = df.index.name[-1]\n",
    "        \n",
    "    df.columns = [col[0] if not isinstance(col, str) else col for col in df.columns]\n",
    "    \n",
    "    table_md = df.to_markdown()\n",
    "    \n",
    "    return table_md\n",
    "\n",
    "def remove_empty_index_col(df):\n",
    "    if 'Unnamed: 0' not in df.columns:\n",
    "        return df\n",
    "    \n",
    "    if (df['Unnamed: 0']==pd.Series(range(df.shape[0]), name='Unnamed: 0')).mean()==1:\n",
    "        df = df.drop(columns=['Unnamed: 0'])\n",
    "    \n",
    "    return df\n",
    "\n",
    "def extract_div_to_md_table(start_idx, end_idx, table_and_div_tags, file_txt):\n",
    "    n_start_divs_before = table_and_div_tags[:start_idx].count('<div>')\n",
    "    n_end_divs_before = table_and_div_tags[:end_idx].count('</div>')\n",
    "    \n",
    "    div_start_idx = get_substring_idxs(file_txt, '<div>')[n_start_divs_before-1]\n",
    "    div_end_idx = get_substring_idxs(file_txt, '</div>')[n_end_divs_before]\n",
    "\n",
    "    div_txt = file_txt[div_start_idx:div_end_idx]\n",
    "    potential_dfs = pd.read_html(div_txt)\n",
    "    \n",
    "    assert len(potential_dfs) == 1, 'Multiple tables were found when there should be only one'\n",
    "    df = potential_dfs[0]\n",
    "    df = remove_empty_index_col(df)\n",
    "    md_table = convert_df_to_md(df)\n",
    "\n",
    "    return div_txt, md_table\n",
    "\n",
    "def extract_div_to_md_tables(md_fp):\n",
    "    with open(md_fp, 'r') as f:\n",
    "        file_txt = f.read()\n",
    "        \n",
    "    parser = MyHTMLParser()\n",
    "    parser.feed(file_txt)\n",
    "\n",
    "    table_and_div_tags = [tag for tag in parser.tags if tag in ['<div>', '</div>', '<table border=\"1\" class=\"dataframe\">', '</table>']]\n",
    "    \n",
    "    table_start_tag_idxs = [i for i, tag in enumerate(table_and_div_tags) if tag=='<table border=\"1\" class=\"dataframe\">']\n",
    "    table_end_tag_idxs = [table_start_tag_idx+table_and_div_tags[table_start_tag_idx:].index('</table>') for table_start_tag_idx in table_start_tag_idxs]\n",
    "\n",
    "    div_to_md_tables = []\n",
    "\n",
    "    for start_idx, end_idx in zip(table_start_tag_idxs, table_end_tag_idxs):\n",
    "        div_txt, md_table = extract_div_to_md_table(start_idx, end_idx, table_and_div_tags, file_txt)\n",
    "        div_to_md_tables += [(div_txt, md_table)]\n",
    "        \n",
    "    return div_to_md_tables\n",
    "\n",
    "def clean_md_file_tables(md_fp):\n",
    "    div_to_md_tables = extract_div_to_md_tables(md_fp)\n",
    "    \n",
    "    with open(md_fp, 'r') as f:\n",
    "        md_file_text = f.read()\n",
    "\n",
    "    for div_txt, md_txt in div_to_md_tables:\n",
    "        md_file_text = md_file_text.replace(div_txt, md_txt)\n",
    "\n",
    "    with open(md_fp, 'w') as f:\n",
    "        f.write(md_file_text)\n",
    "        \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "68c5fb08",
   "metadata": {},
   "outputs": [],
   "source": [
    "md_fp = '../docs/01-utils.md'\n",
    "\n",
    "clean_md_file_tables(md_fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ea4f18-12e9-4900-9166-c23f8fe11e4a",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "We'll add a short function for cleaning the progress bar output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c98290bc-95c9-41ec-9a8d-fe4c0f2bfabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#exports\n",
    "def clean_progress_bars(md_fp, dodgy_char='Ã¢â€“Ë†'):    \n",
    "    with open(md_fp, 'r') as f:\n",
    "        md_file_text = f.read()\n",
    "\n",
    "    md_file_text = md_file_text.replace(f'|{dodgy_char}', '').replace(f'{dodgy_char}|', '').replace(dodgy_char, '')\n",
    "\n",
    "    with open(md_fp, 'w') as f:\n",
    "        f.write(md_file_text)\n",
    "        \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f3a61b33-1913-4730-b146-437b46184c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_progress_bars(md_fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de40c339-05c8-4072-b437-01aed2a2fe0c",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "We'll also correct the filepaths of the notebook images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8a2d5324",
   "metadata": {},
   "outputs": [],
   "source": [
    "#exports\n",
    "def correct_png_name(incorrect_png_name, md_fp):\n",
    "    cell, output = incorrect_png_name.split('_')[1:]\n",
    "    filename = md_fp.split('/')[-1][:-3]\n",
    "    \n",
    "    corrected_png_name = f\"{filename}_cell_{int(cell)+1}_output_{output}\"\n",
    "    \n",
    "    return corrected_png_name\n",
    "\n",
    "get_nb_naive_png_names = lambda img_dir: [f[:-4] for f in os.listdir(img_dir) if f[:6]=='output']\n",
    "\n",
    "def specify_nb_in_img_fp(md_fp, img_dir='img/nbs'):\n",
    "    nb_naive_png_names = get_nb_naive_png_names(img_dir)\n",
    "    nb_specific_png_names = [correct_png_name(nb_naive_png_name, md_fp) for nb_naive_png_name in nb_naive_png_names]\n",
    "\n",
    "    for nb_naive_png_name, nb_specific_png_name in zip(nb_naive_png_names, nb_specific_png_names):\n",
    "        old_img_fp = f'{img_dir}/{nb_naive_png_name}.png'\n",
    "        new_img_fp = f'{img_dir}/{nb_specific_png_name}.png'\n",
    "\n",
    "        os.remove(new_img_fp) if os.path.exists(new_img_fp) else None\n",
    "        os.rename(old_img_fp, new_img_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "19515636",
   "metadata": {},
   "outputs": [],
   "source": [
    "specify_nb_in_img_fp(md_fp, img_dir=docs_nb_img_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e306310",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "And finally clean the filepaths and filenames for any images in the notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0d28c911",
   "metadata": {},
   "outputs": [],
   "source": [
    "#exports\n",
    "def get_filename_correction_map(md_file_text, md_fp):\n",
    "    png_idxs = [png_str.start() for png_str in re.finditer('.png\\)', md_file_text)] \n",
    "    png_names = [md_file_text[:png_idx].split('/')[-1] for png_idx in png_idxs]\n",
    "\n",
    "    filename_correction_map = {\n",
    "        f'{png_name}.png': f'{correct_png_name(png_name, md_fp)}.png'\n",
    "        for png_name \n",
    "        in png_names\n",
    "        if png_name[:6] == 'output' \n",
    "    }\n",
    "\n",
    "    return filename_correction_map\n",
    "\n",
    "def clean_md_text_img_fps(md_file_text, md_fp):\n",
    "    md_file_text = md_file_text.replace('../docs/img/nbs', 'img/nbs')\n",
    "\n",
    "    filename_correction_map = get_filename_correction_map(md_file_text, md_fp)\n",
    "\n",
    "    for incorrect_name, correct_name in filename_correction_map.items():\n",
    "        md_file_text = md_file_text.replace(incorrect_name, correct_name)\n",
    "        \n",
    "    return md_file_text\n",
    "\n",
    "def clean_md_files_img_fps(md_fp):\n",
    "    with open(md_fp, 'r') as f:\n",
    "        md_file_text = f.read()\n",
    "\n",
    "    md_file_text = clean_md_text_img_fps(md_file_text, md_fp)\n",
    "\n",
    "    with open(md_fp, 'w') as f:\n",
    "        f.write(md_file_text)\n",
    "        \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "aeeb9f0a-1edb-4410-9d78-c143f91076f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_md_file_tables(md_fp)\n",
    "clean_progress_bars(md_fp)\n",
    "specify_nb_in_img_fp(md_fp, img_dir=docs_nb_img_dir)\n",
    "clean_md_files_img_fps(md_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e33d0b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sometimes have to add `encoding=\"utf-8\"` to `convert_md` in nbdev "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "65754405",
   "metadata": {},
   "outputs": [],
   "source": [
    "#exports\n",
    "def convert_and_clean_nb_to_md(nbs_dir, docs_nb_img_dir, docs_dir):\n",
    "    nb_files = [f for f in os.listdir(nbs_dir) if f[-6:]=='.ipynb' and f!='00-documentation.ipynb']\n",
    "\n",
    "    for nb_file in tqdm(nb_files):\n",
    "        convert_nb_to_md(nb_file, nbs_dir, docs_nb_img_dir, docs_dir)\n",
    "        \n",
    "        md_fp = docs_dir + '/' + nb_file.replace('ipynb', 'md')\n",
    "    \n",
    "        clean_md_file_tables(md_fp)\n",
    "        clean_progress_bars(md_fp)\n",
    "        specify_nb_in_img_fp(md_fp, img_dir=docs_nb_img_dir)\n",
    "        clean_md_files_img_fps(md_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3e3ae39c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:05<00:00,  1.87it/s]\n"
     ]
    }
   ],
   "source": [
    "for nb_dir in [dev_nbs_dir]:\n",
    "    convert_and_clean_nb_to_md(nb_dir, docs_nb_img_dir, docs_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BMRS",
   "language": "python",
   "name": "bmrs"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
